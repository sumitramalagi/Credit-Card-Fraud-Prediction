{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit card fraud is a wide-ranging term for theft and fraud committed using or involving a payment card, such as a credit card or debit card, as a fraudulent source of funds in a transaction. I have used credit card fraud dataset obatined from kaggle (https://www.kaggle.com/mlg-ulb/creditcardfraud ) to detect credit card fraud.\n",
    "1. Exploratory data analysis\n",
    "2. Split data into train and test. Normalise Data.\n",
    "3. Train a MLP:\n",
    "     a. With two hidden layers (8nodes and 4nodes) and one output layer (2 nodes)\n",
    "     b. Relu activation\n",
    "     c. Adam Optimizer\n",
    "4. Train Autoencoder-Decoder\n",
    "     a. Encoder of 8 nodes\n",
    "     b. tanh activation\n",
    "     c. RMSProp Optimiser\n",
    "     d.Use auc score to validate the result\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score as auc \n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31 features three of which are time, amount and label(class). Others are obtained after dimensionality reduction using PCA to keep the user data private."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no null value in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is unbalanced with only 492 fradulent enteries out of 284807 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "df.sort_values('Time', inplace = True)\n",
    "df=df[:25000]\n",
    "X_train, X_test = train_test_split(df, test_size=0.25, random_state=42)\n",
    "y_train = X_train['Class']\n",
    "y_test = X_test['Class']\n",
    "y_train1 = X_train['Class']\n",
    "y_test1 = X_test['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10827270190304489385\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = StandardScaler(with_mean=False).fit_transform(X_train)\n",
    "X_test = StandardScaler(with_mean=False).fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter intialisation\n",
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "learning_rate = 0.001\n",
    "\n",
    "n_input = X_train.shape[1]\n",
    "n_hidden_1 =8\n",
    "n_hidden_2 = 4\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialising placeholders\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_input])\n",
    "y_ = tf.placeholder(tf.int32, shape=[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising weights and biases\n",
    "weights= {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_2, n_classes])),\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.zeros([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.zeros([n_classes])),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relu Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden_layer_1 =  tf.nn.relu(tf.add(tf.matmul(X, weights['h1']), biases['b1']))\n",
    "hidden_layer_2 =  tf.nn.relu(tf.add(tf.matmul(hidden_layer_1, weights['h2']), biases['b2']))\n",
    "out_layer = tf.add(tf.matmul(hidden_layer_2, weights['out']), biases['b3'])\n",
    "pred_probs = tf.nn.softmax(out_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-e54645bbfb89>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=out_layer))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss= 0.395792812 Auc Value= 0.446548\n",
      "Epoch: 0002 loss= 0.290122271 Auc Value= 0.448552\n",
      "Epoch: 0003 loss= 0.163585544 Auc Value= 0.450091\n",
      "Epoch: 0004 loss= 0.151765630 Auc Value= 0.451070\n",
      "Epoch: 0005 loss= 0.193790928 Auc Value= 0.453087\n",
      "Epoch: 0006 loss= 0.227496713 Auc Value= 0.455138\n",
      "Epoch: 0007 loss= 0.236617491 Auc Value= 0.455749\n",
      "Epoch: 0008 loss= 0.142748922 Auc Value= 0.457164\n",
      "Epoch: 0009 loss= 0.134193167 Auc Value= 0.457846\n",
      "Epoch: 0010 loss= 0.186997682 Auc Value= 0.458721\n",
      "Epoch: 0011 loss= 0.096065715 Auc Value= 0.460010\n",
      "Epoch: 0012 loss= 0.102554210 Auc Value= 0.461164\n",
      "Epoch: 0013 loss= 0.187635824 Auc Value= 0.462299\n",
      "Epoch: 0014 loss= 0.100742072 Auc Value= 0.463049\n",
      "Epoch: 0015 loss= 0.169581801 Auc Value= 0.463922\n",
      "Epoch: 0016 loss= 0.109514125 Auc Value= 0.464569\n",
      "Epoch: 0017 loss= 0.136733741 Auc Value= 0.465322\n",
      "Epoch: 0018 loss= 0.160967365 Auc Value= 0.465747\n",
      "Epoch: 0019 loss= 0.122621067 Auc Value= 0.465869\n",
      "Epoch: 0020 loss= 0.153940678 Auc Value= 0.466207\n",
      "Optimization Finished!\n",
      "Test auc score: 0.4162690152121698\n"
     ]
    }
   ],
   "source": [
    "# Convert Y to a numpy array and split train and validation data (80:20)\n",
    "\n",
    "Y = np.zeros((df.shape[0], 2))\n",
    "Y[range(df.shape[0]), df['Class'].values] = 1              #one hot encoding\n",
    "x_train = X_train[:int(X_train.shape[0] * (0.8))]\n",
    "y_train = Y[:int(X_train.shape[0] *(0.8) )]\n",
    "y_test = Y[X_train.shape[0]:]\n",
    "validation_x = X_train[int(X_train.shape[0] *  (0.2)):]\n",
    "validation_y = Y[int(X_train.shape[0] * (0.2)):X_train.shape[0]]\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    total_batch = int(X_train.shape[0]/batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(n_epochs):\n",
    "        # Loop over all mini batches\n",
    "        for i in range(total_batch):\n",
    "            batch_idx = np.random.choice(x_train.shape[0], batch_size)\n",
    "            batch_xs = x_train[batch_idx]\n",
    "            batch_ys = y_train[batch_idx]\n",
    "            # Run optimiser\n",
    "            _, c = sess.run([optimizer, cross_entropy], feed_dict={X: batch_xs, y_: batch_ys})\n",
    "\n",
    "\n",
    "        #Display logs per epoch step\n",
    "        val_probs = sess.run(pred_probs, feed_dict={X: validation_x})\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1),\n",
    "              \"loss=\", \"{:.9f}\".format(c), \n",
    "              \"Auc Value=\", \"{:.6f}\".format(auc(validation_y[:, 1], val_probs[:, 1])))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    test_probs = sess.run(pred_probs, feed_dict={X: X_test})\n",
    "    \n",
    "    print(\"Test auc score: {}\".format(auc(y_test[:, 1], test_probs[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise placeholder, weights and biases\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'w2': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_input])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Hidden layer with tanh activation\n",
    "encoder_layer_1 = tf.nn.tanh(tf.add(tf.matmul(X, weights['w1']), biases['b1']))\n",
    "decoder_layer_1 = tf.nn.tanh(tf.add(tf.matmul(encoder_layer_1, weights['w2']),biases['b2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted Y\n",
    "y_pred = decoder_layer_1\n",
    "#True Y\n",
    "y_true = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean square error\n",
    "batch_mse = tf.reduce_mean(tf.pow(y_true - y_pred, 2), 1)\n",
    "\n",
    "# Define loss and RMSProp Optimizer, minimize the squared error\n",
    "loss = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss= 1.736669660 Train Auc= 0.997516\n",
      "Epoch: 0002 loss= 1.494547486 Train Auc= 0.997532\n",
      "Epoch: 0003 loss= 1.819013476 Train Auc= 0.997541\n",
      "Epoch: 0004 loss= 1.213060141 Train Auc= 0.997556\n",
      "Epoch: 0005 loss= 1.621577978 Train Auc= 0.997563\n",
      "Epoch: 0006 loss= 1.089150071 Train Auc= 0.997583\n",
      "Epoch: 0007 loss= 0.933269382 Train Auc= 0.997580\n",
      "Epoch: 0008 loss= 1.380723596 Train Auc= 0.997597\n",
      "Epoch: 0009 loss= 1.258286715 Train Auc= 0.997616\n",
      "Epoch: 0010 loss= 0.810753524 Train Auc= 0.997624\n",
      "Epoch: 0011 loss= 0.893336356 Train Auc= 0.997627\n",
      "Epoch: 0012 loss= 0.925928354 Train Auc= 0.997637\n",
      "Epoch: 0013 loss= 0.797889352 Train Auc= 0.997649\n",
      "Epoch: 0014 loss= 0.883463025 Train Auc= 0.997657\n",
      "Epoch: 0015 loss= 0.983460784 Train Auc= 0.997657\n",
      "Epoch: 0016 loss= 0.688339233 Train Auc= 0.997660\n",
      "Epoch: 0017 loss= 0.643325567 Train Auc= 0.997652\n",
      "Epoch: 0018 loss= 0.998958409 Train Auc= 0.997655\n",
      "Epoch: 0019 loss= 0.816455722 Train Auc= 0.997661\n",
      "Epoch: 0020 loss= 0.929107070 Train Auc= 0.997661\n",
      "Optimization Finished!\n",
      "Test auc score: 0.997202\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    total_batch = int(X_train.shape[0]/batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(n_epochs):\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_idx = np.random.choice(X_train.shape[0], batch_size)\n",
    "            batch_xs = X_train[batch_idx]\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, loss], feed_dict={X: batch_xs})\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        train_batch_mse = sess.run(batch_mse, feed_dict={X: X_train})\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1),\n",
    "              \"loss=\", \"{:.9f}\".format(c), \n",
    "              \"Train Auc=\", \"{:.6f}\".format(auc(y_train1, train_batch_mse)))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    test_batch_mse = sess.run(batch_mse, feed_dict={X: X_test})\n",
    "    print(\"Test auc score: {:.6f}\".format(auc(y_test1, test_batch_mse)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN StARTS\n",
    "# save_model = os.path.join(data_dir, 'temp_saved_model_1layer.ckpt')\n",
    "# saver = tf.train.Saver()\n",
    "#     save_path = saver.save(sess, save_model)\n",
    "#     print(\"Model saved in file: %s\" % save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto encoder gives test auc score of nearly 99% while MLP gives lower auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
